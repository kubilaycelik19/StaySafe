{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from imutils.video import FPS\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from myUtils.Database_Utils import WorkersDatabase\n",
    "from torchvision import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_name = {\n",
    "    0: \"Emre\",  # 0 etiketinin ismi\n",
    "    1: \"Kubilay\"    # 1 etiketinin ismi\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = WorkersDatabase(db_name=\"Workers.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 19 (3334113721.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 20\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"YÃ¼z tanÄ±ma modelini yÃ¼kle\"\"\"\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 19\n"
     ]
    }
   ],
   "source": [
    "class StaySafe():\n",
    "    def __init__(self, Model_Name: str, face_model_path: str, db_name, width = 1280, height = 1280):\n",
    "        self.Model_Name = Model_Name\n",
    "        self.face_model_name = face_model_path\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self.CreateYoloModel()\n",
    "        self.face_model = self.CreateFaceRecognitionModel()\n",
    "        self.face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.predicted_names = []\n",
    "        self.database = db_name\n",
    "        \n",
    "        # CUDA optimizasyonlarÄ±\n",
    "        if torch.cuda.is_available():\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            torch.backends.cudnn.deterministic = False\n",
    "        \n",
    "    def CreateFaceRecognitionModel(self):\n",
    "        \"\"\"YÃ¼z tanÄ±ma modelini yÃ¼kle\"\"\"\n",
    "        # Modeli yÃ¼kle\n",
    "        checkpoint = torch.load(self.face_model_name, map_location=self.device)\n",
    "        \n",
    "        # ResNet50 modelini oluÅŸtur\n",
    "        model = models.resnet50(pretrained=False)\n",
    "        \n",
    "        # SÄ±nÄ±f sayÄ±sÄ±nÄ± al\n",
    "        num_classes = len(checkpoint['class_names'])\n",
    "        \n",
    "        # Son katmanÄ± gÃ¼ncelle\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Model aÄŸÄ±rlÄ±klarÄ±nÄ± yÃ¼kle\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        # Model sÄ±nÄ±f isimlerini kaydet\n",
    "        self.face_class_names = checkpoint['class_names']\n",
    "        \n",
    "        # Modeli deÄŸerlendirme moduna al\n",
    "        model.to(self.device)\n",
    "        model.eval()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def CreateYoloModel(self): \n",
    "        # Ã‡alÄ±ÅŸÄ±yor\n",
    "        \"\"\"\n",
    "        AynÄ± dizinde olan modeli parametre olarak verebiliriz. (GeliÅŸtirilecek)\n",
    "        \"\"\"\n",
    "        model = YOLO(self.Model_Name)\n",
    "        return model\n",
    "    \n",
    "    def recognize(self, img, labels=label_to_name):\n",
    "        self.predicted_names = []  # ðŸ”¹ Ã–nceki isimleri temizle\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = self.face_detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=3, minSize=(50, 50))\n",
    "\n",
    "        for face in faces:\n",
    "            \n",
    "            x, y, w, h = face\n",
    "            face_roi = img[y:y+h, x:x+w]\n",
    "\n",
    "            resized = cv2.resize(face_roi, (128, 128))\n",
    "            normalize = resized / 255.0\n",
    "            tensor_image = torch.tensor(normalize, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                result = self.face_model(tensor_image)\n",
    "\n",
    "            _, label = torch.max(result, 1)\n",
    "            predicted_label = label[0].item()\n",
    "            predicted_name = labels.get(predicted_label, \"Bilinmeyen\")\n",
    "            self.predicted_names.append(predicted_name)  # ðŸ”¹ Listeye ekleme\n",
    "\n",
    "        return img, self.predicted_names  # ðŸ”¹ Liste olarak dÃ¶n\n",
    "    \n",
    "    def findWorker(self):\n",
    "        if not self.predicted_names:\n",
    "            return [\"Boyle bir calisan bulunamadi.\"]  # ðŸ”¹ BoÅŸ liste yerine anlamlÄ± dÃ¶nÃ¼ÅŸ\n",
    "        workers = []\n",
    "        for name in self.predicted_names:\n",
    "            try:\n",
    "                worker = db.find_employee(name=name)\n",
    "            except:\n",
    "                worker = \"Boyle bir calisan bulunamadi.\"\n",
    "            workers.append(worker)\n",
    "        return workers\n",
    "        \n",
    "    def ImageDetection(self, image_path):\n",
    "        \"\"\"\n",
    "        Verilen gÃ¶rsel dosya yolunu model ile tahminler ve gÃ¶rselleÅŸtirir.\n",
    "        Args:\n",
    "            image_path (str): GÃ¶rsel dosya yolu.\n",
    "            save_path (str, optional): Kaydedilecek dosya yolu. Varsayilan None.\n",
    "        \"\"\"\n",
    "        # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(\"GÃ¶rÃ¼ntÃ¼ yÃ¼klenemedi. LÃ¼tfen dosya yolunu kontrol edin.\")\n",
    "\n",
    "        # Model ile tahmin yap\n",
    "        results = self.model(image)\n",
    "\n",
    "        # SÄ±nÄ±f isimlerini al\n",
    "        class_names = self.model.names\n",
    "\n",
    "        # Tespit edilen tÃ¼m nesneleri al\n",
    "        boxes = results[0].boxes\n",
    "\n",
    "        # Her bir nesne iÃ§in bounding box ve etiket Ã§iz\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # Bounding box koordinatlarÄ±\n",
    "            conf = box.conf[0].item()  # GÃ¼ven skoru\n",
    "            cls = int(box.cls[0])  # SÄ±nÄ±f ID'si\n",
    "            label = class_names[cls]  # SÄ±nÄ±f ismi\n",
    "            text = f\"{label} {conf:.2f}\"\n",
    "\n",
    "            # Bounding box ve etiketi Ã§iz\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # YeÅŸil kutu\n",
    "            cv2.putText(image, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)  # Etiket\n",
    "\n",
    "        # GÃ¶rÃ¼ntÃ¼yÃ¼ matplotlib ile gÃ¶ster\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # OpenCV BGR -> RGB\n",
    "        plt.imshow(image_rgb)\n",
    "        plt.axis('off')  # Eksenleri kaldÄ±r\n",
    "        plt.show()\n",
    "    \n",
    "    def LiveDetection(self, Source):\n",
    "\n",
    "        # Ã‡alÄ±ÅŸÄ±yor\n",
    "\n",
    "        \"\"\"\n",
    "        Tracker'Ä±n Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± kontrol etmek iÃ§in kullanÄ±lÄ±r.\n",
    "        Modelin tespit edeceÄŸi nesneleri gÃ¶sterir.\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        args:\n",
    "        Source: Video dosyasÄ±nÄ±n yolu\n",
    "        Video path yerine 0 yazÄ±lÄ±rsa webcam'den alÄ±r.\n",
    "        \"\"\"\n",
    "        cap = cv2.VideoCapture(Source)\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read(Source)\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            frame = imutils.resize(frame, width=self.width) # pip install imutils\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            # Model ile nesne takibi yap\n",
    "            results = self.model.track(frame, persist=True, verbose=False)  # persist=True: ID'leri korur ancak Ã§izimde kullanmayacaÄŸÄ±z, verbose = Bilgi\n",
    "            \n",
    "            # DetaylarÄ± Ã§izmek iÃ§in bounding box bilgilerini al\n",
    "            for r in results:\n",
    "                for box in r.boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])  # Bounding box koordinatlarÄ±\n",
    "                    conf = box.conf[0].item()  # GÃ¼ven skoru\n",
    "                    conf_text = f\"%{conf * 100:.2f}\"\n",
    "                    cls = int(box.cls[0])  # SÄ±nÄ±f ID'si\n",
    "                    label = self.model.names[cls]  # SÄ±nÄ±f ismi\n",
    "                    text = f\"{label} {conf_text}\"\n",
    "\n",
    "                    # GÃ¼ven skoru belirli bir seviyenin Ã¼stÃ¼ndeyse Ã§iz\n",
    "                    if conf > 0.5:\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # YeÅŸil kutu Ã§iz\n",
    "                        cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)  # SÄ±nÄ±f ismi\n",
    "\n",
    "            # Sonucu gÃ¶ster\n",
    "            cv2.imshow(\"YOLOv8 Tracking (No ID)\", frame)\n",
    "\n",
    "            # 'q' tuÅŸuna basarak Ã§Ä±kÄ±ÅŸ yap\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def SafetyCheckFromImage(self, image_path):\n",
    "        # GÃ¶rÃ¼ntÃ¼yÃ¼ PIL ile yÃ¼kle\n",
    "        image = Image.open(image_path)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "        # Model ile tahmin yap\n",
    "        results = self.model(image)\n",
    "\n",
    "        # SÄ±nÄ±f isimlerini al\n",
    "        class_names = self.model.names\n",
    "\n",
    "        # Tespit edilen tÃ¼m nesneleri al\n",
    "        boxes = results[0].boxes\n",
    "\n",
    "        # TÃ¼m person'larÄ± bul\n",
    "        persons = [box for box in boxes if class_names[int(box.cls)] == 'person']\n",
    "\n",
    "        # Her bir person iÃ§in helmet ve vest kontrolÃ¼ yap\n",
    "        for person in persons:\n",
    "            x1, y1, x2, y2 = map(int, person.xyxy[0])  # Person'un bounding box koordinatlarÄ±nÄ± al\n",
    "            has_helmet = False\n",
    "            has_vest = False\n",
    "\n",
    "            # DiÄŸer tÃ¼m nesneleri kontrol et\n",
    "            for other_box in boxes:\n",
    "                other_class_id = int(other_box.cls)\n",
    "                other_class_name = class_names[other_class_id]\n",
    "                other_x1, other_y1, other_x2, other_y2 = map(int, other_box.xyxy[0])\n",
    "\n",
    "                # EÄŸer helmet veya vest bu person ile aynÄ± bÃ¶lgede ise\n",
    "                if (other_class_name == 'helmet' or other_class_name == 'vest') and \\\n",
    "                (other_x1 > x1 and other_x2 < x2 and other_y1 > y1 and other_y2 < y2):\n",
    "                    if other_class_name == 'helmet':\n",
    "                        has_helmet = True\n",
    "                    elif other_class_name == 'vest':\n",
    "                        has_vest = True\n",
    "\n",
    "            # EÄŸer hem helmet hem de vest varsa, person'u \"Safe\" olarak iÅŸaretle\n",
    "            if has_helmet and has_vest:\n",
    "                draw.rectangle([x1, y1, x2, y2], outline=\"green\", width=2)  # YeÅŸil bbox\n",
    "                draw.text((x1, y1 - 20), \"Safe\", fill=\"green\")  # \"Safe\" yazÄ±sÄ±\n",
    "            # EÄŸer helmet veya vest yoksa, person'u \"Unsafe\" olarak iÅŸaretle\n",
    "            else:\n",
    "                draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)  # KÄ±rmÄ±zÄ± bbox\n",
    "                draw.text((x1, y1 - 20), \"Unsafe\", fill=\"red\")  # \"Unsafe\" yazÄ±sÄ±\n",
    "\n",
    "        # GÃ¶rÃ¼ntÃ¼yÃ¼ matplotlib ile gÃ¶ster\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')  # Eksenleri kaldÄ±r\n",
    "        plt.show()\n",
    "        \n",
    "    def SafetyDetector(self, Source, recognition=False):\n",
    "        cap = cv2.VideoCapture(Source)\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            frame = cv2.flip(frame, 1)\n",
    "            frame = imutils.resize(frame, width=self.width)\n",
    "            \n",
    "            # Model ile tahmin yap\n",
    "            results = self.model(frame, verbose=False)\n",
    "            \n",
    "            # SÄ±nÄ±f isimlerini al\n",
    "            class_names = self.model.names\n",
    "            boxes = results[0].boxes\n",
    "            \n",
    "            # TÃ¼m person'larÄ± bul\n",
    "            persons = [box for box in boxes if class_names[int(box.cls)] == 'person']\n",
    "            \n",
    "            # Her bir person iÃ§in helmet ve vest kontrolÃ¼ yap\n",
    "            for person in persons:\n",
    "                x1, y1, x2, y2 = map(int, person.xyxy[0])\n",
    "                has_helmet = False\n",
    "                has_vest = False\n",
    "                \n",
    "                for other_box in boxes:\n",
    "                    other_class_id = int(other_box.cls)\n",
    "                    other_class_name = class_names[other_class_id]\n",
    "                    other_x1, other_y1, other_x2, other_y2 = map(int, other_box.xyxy[0])\n",
    "                    \n",
    "                    if (other_class_name == 'helmet' or other_class_name == 'vest') and \\\n",
    "                    (other_x1 > x1 and other_x2 < x2 and other_y1 > y1 and other_y2 < y2):\n",
    "                        if other_class_name == 'helmet':\n",
    "                            has_helmet = True\n",
    "                        elif other_class_name == 'vest':\n",
    "                            has_vest = True\n",
    "                \n",
    "                if has_helmet or has_vest:\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, 'Safe', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                else:\n",
    "                    if recognition:\n",
    "                        self.recognize(frame, label_to_name)\n",
    "                        worker = self.findWorker()\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                        cv2.putText(frame, f'{worker}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                    else:\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                        cv2.putText(frame, 'Unsafe', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "            \n",
    "            cv2.imshow('Result', frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stay_safe \u001b[38;5;241m=\u001b[39m \u001b[43mStaySafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModel_Name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/celik/Desktop/ss2/Models/Yolo11n_50_epoch.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mface_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/celik/Desktop/StaySafe/best_face_model.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWorkers.db\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m, in \u001b[0;36mStaySafe.__init__\u001b[1;34m(self, Model_Name, face_model_path, db_name, width, height)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCreateYoloModel()\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mface_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateFaceRecognitionModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mface_detector \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCascadeClassifier(cv2\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mhaarcascades \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhaarcascade_frontalface_default.xml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicted_names \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[4], line 21\u001b[0m, in \u001b[0;36mStaySafe.CreateFaceRecognitionModel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mCreateFaceRecognitionModel\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     20\u001b[0m     face_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mface_model_name, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m---> 21\u001b[0m     \u001b[43mface_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     22\u001b[0m     face_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m face_model\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "stay_safe = StaySafe(Model_Name=\"C:/Users/celik/Desktop/ss2/Models/Yolo11n_50_epoch.pt\", face_model_path=\"C:/Users/celik/Desktop/StaySafe/best_face_model.pth\", db_name=\"Workers.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "safetyCheck_live = stay_safe.SafetyDetector(Source=0, recognition=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
