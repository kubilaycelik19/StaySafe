{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from imutils.video import FPS\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from Database_Utils import WorkersDatabase\n",
    "from torchvision import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_name = {\n",
    "    0: \"Emre\",  # 0 etiketinin ismi\n",
    "    1: \"Kubilay\"    # 1 etiketinin ismi\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = WorkersDatabase(db_name=\"Workers.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaySafe():\n",
    "    def __init__(self, Model_Name: str, face_model_path: str, db_name, width = 1280, height = 1280):\n",
    "        self.Model_Name = Model_Name\n",
    "        self.face_model_name = face_model_path\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self.CreateYoloModel()\n",
    "        self.face_model = self.CreateFaceRecognitionModel()\n",
    "        self.face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.predicted_names = []\n",
    "        self.database = db_name\n",
    "        \n",
    "        # CUDA optimizasyonlarÄ±\n",
    "        if torch.cuda.is_available():\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            torch.backends.cudnn.deterministic = False\n",
    "        \n",
    "    def CreateFaceRecognitionModel(self):\n",
    "        \"\"\"YÃ¼z tanÄ±ma modelini yÃ¼kle\"\"\"\n",
    "        # Modeli yÃ¼kle\n",
    "        checkpoint = torch.load(self.face_model_name, map_location=self.device)\n",
    "        \n",
    "        # Mobilenet_v3_small modelini oluÅŸtur\n",
    "        model = models.mobilenet_v3_small(pretrained=True)\n",
    "        \n",
    "        # SÄ±nÄ±f sayÄ±sÄ±nÄ± al\n",
    "        num_classes = len(checkpoint['class_names'])\n",
    "        \n",
    "        # Son katmanÄ± gÃ¼ncelle\n",
    "        num_features = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Model aÄŸÄ±rlÄ±klarÄ±nÄ± yÃ¼kle\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        # Model sÄ±nÄ±f isimlerini kaydet\n",
    "        self.face_class_names = checkpoint['class_names']\n",
    "        \n",
    "        # Modeli deÄŸerlendirme moduna al\n",
    "        model.to(self.device)\n",
    "        model.eval()\n",
    "    \n",
    "        return model\n",
    "    \n",
    "    def CreateYoloModel(self): \n",
    "        # Ã‡alÄ±ÅŸÄ±yor\n",
    "        \"\"\"\n",
    "        AynÄ± dizinde olan modeli parametre olarak verebiliriz. (GeliÅŸtirilecek)\n",
    "        \"\"\"\n",
    "        model = YOLO(self.Model_Name)\n",
    "        return model\n",
    "    \n",
    "    def recognize(self, img, labels=label_to_name):\n",
    "        self.predicted_names = []  # ğŸ”¹ Ã–nceki isimleri temizle\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = self.face_detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=3, minSize=(50, 50))\n",
    "\n",
    "        for face in faces:\n",
    "            \n",
    "            x, y, w, h = face\n",
    "            face_roi = img[y:y+h, x:x+w]\n",
    "\n",
    "            resized = cv2.resize(face_roi, (128, 128))\n",
    "            normalize = resized / 255.0\n",
    "            tensor_image = torch.tensor(normalize, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                result = self.face_model(tensor_image)\n",
    "\n",
    "            _, label = torch.max(result, 1)\n",
    "            predicted_label = label[0].item()\n",
    "            predicted_name = labels.get(predicted_label, \"Bilinmeyen\")\n",
    "            self.predicted_names.append(predicted_name)  # ğŸ”¹ Listeye ekleme\n",
    "\n",
    "        return img, self.predicted_names  # ğŸ”¹ Liste olarak dÃ¶n\n",
    "    \n",
    "    def findWorker(self):\n",
    "        if not self.predicted_names:\n",
    "            return [\"Boyle bir calisan bulunamadi.\"]  # ğŸ”¹ BoÅŸ liste yerine anlamlÄ± dÃ¶nÃ¼ÅŸ\n",
    "        workers = []\n",
    "        for name in self.predicted_names:\n",
    "            try:\n",
    "                worker = db.find_employee(name=name)\n",
    "            except:\n",
    "                worker = \"Boyle bir calisan bulunamadi.\"\n",
    "            workers.append(worker)\n",
    "        return workers\n",
    "    \n",
    "    def SafetyDetector(self, Source, recognition=False):\n",
    "        cap = cv2.VideoCapture(Source)\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            frame = cv2.flip(frame, 1)\n",
    "            frame = imutils.resize(frame, width=self.width)\n",
    "            \n",
    "            # Model ile tahmin yap\n",
    "            results = self.model(frame, verbose=False)\n",
    "            \n",
    "            # SÄ±nÄ±f isimlerini al\n",
    "            class_names = self.model.names\n",
    "            boxes = results[0].boxes\n",
    "            \n",
    "            # TÃ¼m person'larÄ± bul\n",
    "            persons = [box for box in boxes if class_names[int(box.cls)] == 'person']\n",
    "            \n",
    "            # Her bir person iÃ§in helmet ve vest kontrolÃ¼ yap\n",
    "            for person in persons:\n",
    "                x1, y1, x2, y2 = map(int, person.xyxy[0])\n",
    "                has_helmet = False\n",
    "                has_vest = False\n",
    "                \n",
    "                for other_box in boxes:\n",
    "                    other_class_id = int(other_box.cls)\n",
    "                    other_class_name = class_names[other_class_id]\n",
    "                    other_x1, other_y1, other_x2, other_y2 = map(int, other_box.xyxy[0])\n",
    "                    \n",
    "                    if (other_class_name == 'helmet' or other_class_name == 'vest') and \\\n",
    "                    (other_x1 > x1 and other_x2 < x2 and other_y1 > y1 and other_y2 < y2):\n",
    "                        if other_class_name == 'helmet':\n",
    "                            has_helmet = True\n",
    "                        elif other_class_name == 'vest':\n",
    "                            has_vest = True\n",
    "                \n",
    "                if has_helmet or has_vest:\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, 'Safe', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                else:\n",
    "                    if recognition:\n",
    "                        self.recognize(frame, label_to_name)\n",
    "                        worker = self.findWorker()\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                        cv2.putText(frame, f'{worker}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                    else:\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                        cv2.putText(frame, 'Unsafe', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "            \n",
    "            cv2.imshow('Result', frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\celik\\anaconda3\\envs\\cvEnv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\celik\\anaconda3\\envs\\cvEnv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "stay_safe = StaySafe(Model_Name=\"../StaySafe/Yolo11n_50_epoch.pt\", face_model_path=\"../best_face_model.pth\", db_name=\"Workers.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "safetyCheck_live = stay_safe.SafetyDetector(Source=0, recognition=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
